{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b439967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d59f806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.1\n",
      "90100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.cuda.is_available())  # 應該為 True\n",
    "print(torch.version.cuda)         # 應該列出 CUDA 版本\n",
    "print(torch.backends.cudnn.version())  # cuDNN 版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9d18a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.path.join(os.getcwd(), 'space_ship_game_RL')\n",
    "if script_dir not in sys.path:\n",
    "    sys.path.append(script_dir)\n",
    "\n",
    "from setting import *\n",
    "from game import Game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1809ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpaceShipEnv():\n",
    "    def __init__(self):\n",
    "        pygame.init()\n",
    "        pygame.font.init()\n",
    "\n",
    "        # 延後畫面初始化，等 render() 時才設置\n",
    "        self.screen = None\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.fps = FPS\n",
    "\n",
    "        self.game = Game()\n",
    "\n",
    "        self.action_space = [0, 1, 2, 3]\n",
    "        self.observation = self.game.state\n",
    "        self.prev_score = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        self.game.update(action)\n",
    "\n",
    "        if self.screen is None:\n",
    "            self.game.draw()\n",
    "        else:\n",
    "            self.game.draw(self.screen)\n",
    "            self.clock.tick(self.fps)\n",
    "\n",
    "        # define the state by your game logic\n",
    "        state = self.game.state\n",
    "\n",
    "        # define the reward by your game logic\n",
    "        reward  = 0.0\n",
    "\n",
    "        # reward += (self.game.score - self.prev_score) * 0.1\n",
    "        reward += self.game.is_hit_rock * 80\n",
    "\n",
    "        reward += self.game.is_power * 50\n",
    "\n",
    "        reward -= self.game.is_collided * 100\n",
    "\n",
    "        reward += 0.01\n",
    "        \n",
    "        reward += (self.game.score - self.prev_score) * 0.1\n",
    "        self.prev_score = self.game.score\n",
    "        done = not self.game.running or self.game.score >= 10000\n",
    "        info = {\n",
    "            \"score\": self.game.score,\n",
    "            \"health\": self.game.player.sprite.health\n",
    "        }\n",
    "        return state, reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self.game = Game()\n",
    "\n",
    "        return self.game.state\n",
    "\n",
    "    def render(self):\n",
    "        if self.screen is None:\n",
    "            self.screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "            pygame.display.set_caption(\"SpaceShip RL Environment\")\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf358210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2b584f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-based DQN Model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, in_channels, num_actions):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=8, stride=4),  # (C,84,84)→(32,20,20)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),           # →(64,9,9)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),           # →(64,7,7)\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_actions)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x / 255.0) \n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "30848ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess frames (grayscale and resize to 84x84)\n",
    "# 預處理影格：轉為灰階並縮放為 84x84\n",
    "import cv2\n",
    "def preprocess_state(state, stacked_state=None, is_new=False):\n",
    "    gray = cv2.cvtColor(state, cv2.COLOR_RGB2GRAY)\n",
    "    gray = cv2.resize(gray, (84, 84), interpolation=cv2.INTER_AREA)\n",
    "    gray = torch.tensor(gray, dtype=torch.uint8).unsqueeze(0)        # (1,84,84)\n",
    "    if is_new or stacked_state is None:\n",
    "        stacked_state = gray.repeat(4, 1, 1)                         # (4,84,84)\n",
    "    else:\n",
    "        stacked_state = torch.cat((gray, stacked_state[:-1]), dim=0)\n",
    "    return stacked_state.float().unsqueeze(0), stacked_state         # (1,4,84,84)\n",
    "\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    # frame 是 numpy array (H, W, 3)，先轉為 PIL Image\n",
    "    # Input is a color image (RGB), convert to PIL format for easier processing.\n",
    "    # 輸入是彩色圖像（RGB），轉成 PIL Image 以方便處理。\n",
    "    image = Image.fromarray(frame)\n",
    "\n",
    "    # 轉灰階\n",
    "    # Convert the image to grayscale to reduce input complexity.\n",
    "    # 將影像轉為灰階，降低輸入維度與計算量。\n",
    "    image = image.convert('L')\n",
    "\n",
    "    # resize 成 84x84\n",
    "    # Resize the image to a standard 84x84 shape, as per DQN convention.\n",
    "    # 依照 DQN 的慣例將影像統一縮放至 84x84。\n",
    "    image = image.resize((84, 84), Image.Resampling.BILINEAR)  # or NEAREST, or LANCZOS\n",
    "\n",
    "    # 轉回 numpy 並正規化\n",
    "    # Convert back to NumPy and normalize pixel values to [0, 1].\n",
    "    # 轉回 NumPy 格式並將像素值標準化到 [0, 1]。\n",
    "    frame = np.asarray(image, dtype=np.float32) / 255.0\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def stack_frames(stacked_frames, state, is_new_episode):\n",
    "    # 預處理目前影格\n",
    "    frame = preprocess_frame(state)\n",
    "\n",
    "    if is_new_episode or stacked_frames is None:\n",
    "        # If it's a new episode or no previous frames, initialize with 4 identical frames\n",
    "        # 若是新的一集或是尚未初始化，則用目前影格複製 4 次形成初始堆疊\n",
    "        stacked_frames = deque([frame]*4, maxlen=4)\n",
    "    else:\n",
    "        # 否則把新影格加入到堆疊中，自動捨棄最舊的\n",
    "        stacked_frames.append(frame)\n",
    "\n",
    "    # Stack the 4 frames along the first dimension: shape becomes (4, 84, 84)\n",
    "    # 沿著第一維（channel）堆疊成 4 通道輸入：形狀變成 (4, 84, 84)\n",
    "    stacked_state = np.stack(stacked_frames, axis=0)\n",
    "\n",
    "    return stacked_state, stacked_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f81e7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_16472\\932155778.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('checkpoint_V2.pth', map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=3136, out_features=512, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=512, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_actions = 4  # Breakout 中的動作數量（例如：無動作、左移、右移、發球）  \n",
    "i_channels = 4  # 堆疊的影格數量（例如：4 個連續影格）\n",
    "# Number of possible actions in Breakout (e.g., NOOP, LEFT, RIGHT, FIRE)\n",
    "\n",
    "model = DQN(i_channels, num_actions).to(device)  \n",
    "# 建立 DQN 模型並放到指定裝置（CPU 或 GPU）  \n",
    "# Create a DQN model and move it to the specified device (CPU or GPU)\n",
    "\n",
    "checkpoint = torch.load('checkpoint_V2.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['policy_net'])\n",
    "# 載入訓練好的模型權重（可跨裝置載入）  \n",
    "# Load trained model weights (supports device mapping for CPU/GPU compatibility)\n",
    "\n",
    "model.eval()  \n",
    "# 設定模型為評估模式，關閉 dropout/batchnorm 等訓練特性  \n",
    "# Set the model to evaluation mode (disables dropout, batchnorm, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15bcece",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     frame \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(frame, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m))     \u001b[38;5;66;03m# pygame 是 x,y → imageio 是 y,x\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(frame)\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m env\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mKeyError\u001b[0m: 'score'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在目前儲存格或上一個儲存格中執行程式碼時，Kernel 已損毀。\n",
      "\u001b[1;31m請檢閱儲存格中的程式碼，找出失敗的可能原因。\n",
      "\u001b[1;31m如需詳細資訊，請按一下<a href='https://aka.ms/vscodeJupyterKernelCrash'>這裡</a>。\n",
      "\u001b[1;31m如需詳細資料，請檢視 Jupyter <a href='command:jupyter.viewOutput'>記錄</a>。"
     ]
    }
   ],
   "source": [
    "# Visualization of trained agent\n",
    "env = SpaceShipEnv()\n",
    "env.render()\n",
    "state_raw = env.reset()\n",
    "stacked_frames = None\n",
    "state_b, state = preprocess_state(state_raw, None, True)  # 使用 preprocess_state 初始化\n",
    "done = False\n",
    "frames = []\n",
    "\n",
    "while not done:\n",
    "    state_tensor = state_b.to(device)\n",
    "    q_values = model(state_tensor)\n",
    "    action = torch.argmax(q_values, dim=1).item()\n",
    "\n",
    "    next_state_raw, reward, done, info = env.step(action)\n",
    "    next_state_b, next_state = preprocess_state(next_state_raw, state, False)  # 使用 preprocess_state 更新狀態\n",
    "    state_b, state = next_state_b, next_state\n",
    "\n",
    "    # 把畫面抓下來（RGB）\n",
    "    surface = pygame.display.get_surface()\n",
    "    frame = pygame.surfarray.array3d(surface)  # shape: (W, H, 3)\n",
    "    frame = np.transpose(frame, (1, 0, 2))     # pygame 是 x,y → imageio 是 y,x\n",
    "    frames.append(frame)\n",
    "\n",
    "print(f\"reward: {reward}, score: {info['score']}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06fbf4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892\n"
     ]
    }
   ],
   "source": [
    "print(len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a2fc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (250, 300) to (256, 304) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved gameplay video to: space_ship_run_rl_V4_1.mp4\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "video_path = \"space_ship_run_rl_V4_1.mp4\"\n",
    "\n",
    "imageio.mimsave(video_path, frames, fps=60, quality=9)\n",
    "print(f\"Saved gameplay video to: {video_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
